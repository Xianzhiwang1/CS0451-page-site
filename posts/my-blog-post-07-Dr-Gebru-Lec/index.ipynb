{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Reflection on Dr. Gebru's recorded lecture and questions for upcomming talks \n",
    "author: Xianzhi Wang \n",
    "date: '2023-04-12'\n",
    "image: \"image.png\"\n",
    "description: \"My blog post on Dr. Gebru's recorded lecture and questions for upcomming talkes\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to Source Code \n",
    "[Here](https://github.com/Xianzhiwang1/CS0451-page-site/tree/main/posts/) is a link to the source code for this post.\n",
    "\n",
    "### Link to reference for this blog post\n",
    "[Here](https://middlebury-csci-0451.github.io/CSCI-0451/assignments/blog-posts/blog-post-guest-speaker.html) is a link to the main reference we use as we implement this post."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "Dr. Timnit Gebru is scheduled to give a talk at Middlebury College on April 24th at 7:00 PM ET in Hillcrest 103, titled \"Eugenics and the Promise of Utopia through Artificial General Intelligence.\" I am interested in learning more about her field of study and what she would like to address during the talk. Dr. Gebru is a high-achieving academic working broadly in the field of computer vision. She holds a PhD in Computer Science from Stanford, and she is very active in academia and industry alike. \n",
    "\n",
    "Trained in her doctorial study as a computer scientist, Dr. Gebru works on algorithmic bias and data mining. She has extensive experience working in research teams at Microsoft, Google, and Apple, and she is a recognized voice in artificial intelligence and ethical frameworks, because of the extensive research experience she had, and the projects and programs she involved in. She is a cofounder of Black in AI, and she is the founder of the Distributed Artificial Intelligence Research Institute. She is very influential and recognized, and she is named one of Time's most influential people. She is also named as one of World's 50 Greatest Leaders by Fortune and one of Nature's ten people who shaped science in 2021, according to Wikipedia. She is also active on social media such as LinkedIn, and she is also very active academically, authoring peer reviewed publications and traveling widely and giving talks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Reflection about Dr Gebru's previous talk on Fairness, Accountability, Transparency, and Ethics.\n",
    "The thesis of Dr. Gebru’s lecture is that computer vision is a double edged sword, and if used inappropriately, it could greatly increase systematic racism, racial bias, gender bias, and all types of bias in a society, and greatly harm the population for whom the computer vision is used on. Here, there is a lot of responsibility regarding the use of computer vision, and there are a lot of ethical choices to be made. \n",
    "\n",
    "Data, computer vision, and machine learning ethics is a very important topic, and need to be taken into consideration by researchers. For example, a startup called “Faception” is aimed at profiling people and revealing their personality solely based on their facial image and facial expressions. Dr. Gebru invited us to brainstorm what could potentially go wrong here: say, a person is wrongly judged to be angry or hot-tempered, then that person will be denied jobs based on the assessment of this technology called “Faception”. Dr. Gebru went on to talk about HireVue, another startup technology that harnesses artificial intelligence,  facial recognition to screen job candidates, which might be biased against certain minority groups, hence it is unjust and unethical towards the group of people it’s systematically biased against. A third example is Maryland Police department’s usage of facial recognition and screening of protestors and perpetrators, which could lead to all sorts of consequences and arrests. They could even match a protester's profile to their social media accounts, which sounds dreadful, like a nightmare from a sci-fi movie. In conclusion, Dr. Gebru showcased that used carelessly, computer vision and machine learning could do more harm than good.\n",
    "\n",
    "In one sentence, the thing that everyone needs to understand about computer vision as it's used today is that it's a double edged sword, and it could potentially be very biased and harm many people, so it should be used with caution and a dedicated legal, ethical, scientific framework.\n",
    "\n",
    "In conclusion, greater technical advancement carries greater responsiblity, we need more laws, regulations, and ethical considerations when we engage with latest techonology from computer vision and computer science as a whole."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My proposed question for her during Dr. Gebru's talk\n",
    "If everything could start over from 2001, and there is a benevolent social planer who allocates resource efficiently and cares about all humans living on this land, how would you think the field of computer vision would develop differently, and in what ways better, than what we have now in reality? Thanks!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dr. Gebru's guest lecture during class time and my reflection on the process\n",
    "### AI for social good\n",
    "Dr. Gebru draws our attention to the funding source of some of the AI research. She points out that, in certain cases, the funds that supports scientific progress in AI nowadays come from large corporations and the millitary. Dr Gebru stresses that where funds come from matters. She further emphasises that there are many costs of building AI models, and the companies that builds AI could not just unquestionably assume that the AI they are building is beneficial by simply claiming it is beneficial. She stresses that people should take such claims with a grain of salt, and pay attention to some of the negative externalities that those companies could potentially create, such as using online media contents to train AI for free without paying the artists who created those contents. Also, Dr. Gebru mentioned that more people from more diverse backgrounds in the field of AI could potentially address those issues by bringing more perspectives into the field of AI. \n",
    "\n",
    "### Example about potential AI problem: not participate in Social Media\n",
    "To illustrate some of the potential problems of AI, Dr. Gebru gives an example, that there are AIs that classify people, and for people who don't participate in social media platforms, the AI would classify them as outliers, and this is just scary, since using common sense, people should have choices over they want to use social media or not, and they shouldn't be judged like outliers if they simply do not want to maintain a social media presence. \n",
    "\n",
    "### Computer Vision, Dr. Gebru talks about the research field she focuses on\n",
    "Dr Gebru invites us to think about what is computer vision being used for? She gives a rather dreadful example where one researcher left the field of computer visions, even though that person enjoy working on problems in this field. But why did this person leave? Dr. Gebru explains that it was becuase this person feels sad that their research work is going to be used by the military. Dr Gebru further invites us to imagine refugees suffering climate catastrophies, but in many cases, more money was poured into computer vision research than spent on the climate change related initialtives. \n",
    "\n",
    "However, the field of AI is not always this dismal, Dr Gebru mentions one group of scientists from Chicago using computer vision to develop tools to protect the artist instead of exploiting the content they produces. \n",
    "\n",
    "\n",
    "### AI cannot solve everything \n",
    "Dr Gebru further explains that AI is not all powerful, since it cannot solve everything. She gives a mondane example of people who live next to the Nile river need to walk many miles just to get water, and AI cannot get water for them. This is a rather bizarre example, but I might missed the point Dr. Gebru was trying to make since we had internet connection problems over zoom, so I could not hear her complete sentences for a while. In short, she stressed that general AI might not solve everybody's problems. Also, just in order to train deep learning models whould need a lot of labeled image data, and those data are obtained sometimes through the labor of the gig work force, and people are not employed, and they are in general cheap labor exploited by companies to label those images. Dr Gebru laments that some systems like stable diffusion would use works from artists with no compensation for the artists. Hence, the artists are not paid adequately for the work they produced. \n",
    "\n",
    "Furthermore, Dr Gebru mentioned that some of those AI projects that took works, pictures from artists to train AI to work in surveillance, and people are surveillanced especially for people who are migrating from one country to another, and I think the surveillance part of the tale sounds really scary, and it's quite a bleak picture that Dr Gebru painted for us. I feel very depressed. Later, Dr Gebru mentioned that there are good projects that develop AI that help artists, like Glaze, which protects artists. \n",
    "\n",
    "### Dr Gebru answers question: being a women of color in the Computer Science, have you ever felt imposter syndrome?\n",
    "Dr Gebru encouraged everyone to not feel imposter syndrome, and be confident. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dr. Gebru's talk at 7 PM and my reflection on the process \n",
    "\n",
    "### Economic development and open AI\n",
    "Dr Gebru starts by discussing the economical aspects of the AI industry. She points out that there are millions of people in the world who are paid very little to label the data that is used for training AI, and there are also millions of creative contents that are feeded to AI such as chatGPT. Those contents are created by people, artists, human beings, and many times, those artists are not paid by the compinies that trains AIs, and there are also people working in content moderating, who needs to endure a lot of terrible images just so the rest of us do not need to see it. Hence, there's a lot of negative externality associated with AI.\n",
    "\n",
    "### AGI, Artificial General Intelligence\n",
    "AGI stands for Artificial General Intelligence. Dr. Gebru went to introduce the concept of AGI. She looked up the definition of AGI, and there's a defintion by Peter Ross, a definition by Russel, and many more definitions. Dr. Gebru maintains that the definition of AGI is quite vague and general. Then, Dr. Gebru presents one paper about eugenics and AGI that she wrote with her co-authors. Although people often associate eugenics with very bad things such as NAZI germany, Dr. Gebru explains that eugenics is actually a scientific idea that is studied by many scientists before and after the World War Two. She further explains the difference between positive eugenics and negative eugenics. She introduces the Second-Wave Eugenics, which is characteriszed by Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, Longtermism, etc. This is quite different from negative eugenics, which in a highly summarized way, is about removing \"stupid\" genes from the gene pool. However, the positive eugenics is different, and it is about improving the gene pool, as Dr. Gebru summerizes. Then she quickly covers the big terms in the Second-Wave Eugenics, and she admits that those are quite contraversial ideas, and some of these ideas are quite extreme and she does not agree with those ideas. Also, I found many of those ideas disturbing and I feel genuinely depressed after hearing them. At one point, she rolls her eyes and shakes her head about some of the absurd comments and view points she presented. Hence, those are pretty contraversial and hot-debated topics. Some recurrent themes include create superior humans that are going to change the universe, while the rest of us are rendered \"legacy humans,\" which in a absurdist and existential way, on a high level summarized some ideology that this body of critiques is going. \n",
    "\n",
    "Moreover, Dr Gebru ties these second-wave ideas back to the first-wave eugenics, which also contains a lot of controversial ideas. Then Dr. Gebru went on to talk about AGI development, and she discussed the double-edge sword that is AGI. This speech turned very much like a dreadful sci-fi tale that went badly wrong. On one hand, it seems that if everything is done right then we have a benevolent AGI, then there's utopia, but if we build a evil AGI, then we have a apocalypse, like straight out of a Terminator movie. I feel very disturbed by the landscape she painted, and it made me feel dreadful. \n",
    "\n",
    "### History\n",
    "Dr Gebru went on to retrace the history of AI, and there's ebbs and flows of the term AI. In 1956, the term \"AI\" was officially coined. Fast forward to 2010, Deepmind was founded, with the same goal as AI, then in 2014, Bostrom's Superintelligence comes out, and Deepmind is bought by Google. Dr. Gebru kept on going to tie AGI Utopia to the themes she has discussed so far. \n",
    "\n",
    "Basically, there's a race to the bottom with many companies pouring in billions of dollars into building AGI. It seems like the next big thing, and all major tech companies do not want to lose this race to build AGI. However, there is a lot of worrying themes, since it seems like a horror sci-fi story just like one from the Terminator. Since one tech company is racing to build it, all other companies needs to build it, because this is a winner take all market, so if one company created open AI, then that company dominates the market, and other company basically face the fate of Yahoo and goes out. Again, I was deeply troubled by this vision, and I hope we are NOT living in a Terminator movie.\n",
    "\n",
    "\n",
    "### Dr Gebru went on to introduce some good AI researches \n",
    "Dr Gebru maintains that building a single all-powerful AI is not all there is, one could potentially build many AI that speciallize in different tasks. She discusses several cases of combating harmful hype in natural language processing. Some organizations focus on just build language processing. However, those small companies sometimes have trouble with securing funding, since general AI might could do it all. Then Dr. Gebru mentioned some future events such as \"Stochastic Parrot day\", which she encourage people to attend, that further explains this hype about natural language processing.\n",
    "\n",
    "She went on to talk about the AGI Apocalypse, which is basically that they are afraid that they are going to build something that is too powerful, like some sci-fi future, and they are going to create \"skynet\", like in Terminator. However, those concerns about build a sci-fi future that is a apocalypse, are actually a distraction from some acute problems with AI, as Dr. Gebru maintains. Hence, Dr Gebru stress that the more acute problem is that people are exploited when large training AI is going on. This circles back to the point she brings up at the begining of the lecture, that is, many artists are not paid when their work is used to train AI.\n",
    "\n",
    "### Thoughts and Comments\n",
    "Dr Gebru's talk left me very depressed, and I am very troubled by some of the viewpoints she presented when she introduced eugenics, and especially the second wave of eugenics. I disagree with those perspectives that renders almost everyone on this planet \"legacy humans\" and talks about what is basically \"superhumans.\" I am very troubled by those view points, and I found it very discouraging. I think people should learn more about the potential harm AI could have done to society if this power is not used correctly. I am curious about what's going to happen in the field of AI in the next few years.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('ml-0451')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "828d98d954e87c2b5b44e0a5cfd805247874b19ac6d7df6603713eaf15bc89d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
