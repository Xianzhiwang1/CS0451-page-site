{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Reflection on Dr. Gebru's recorded lecture and questions for upcomming talks \n",
    "author: Xianzhi Wang \n",
    "date: '2023-04-12'\n",
    "image: \"image.png\"\n",
    "description: \"My blog post on Dr. Gebru's recorded lecture and questions for upcomming talkes\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to Source Code \n",
    "[Here](https://github.com/Xianzhiwang1/CS0451-page-site/tree/main/posts/) is a link to the source code for this post.\n",
    "\n",
    "### Link to reference for this blog post\n",
    "[Here](https://middlebury-csci-0451.github.io/CSCI-0451/assignments/blog-posts/blog-post-guest-speaker.html) is a link to the main reference we use as we implement this post."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "Dr. Timnit Gebru is scheduled to give a talk at Middlebury College on April 24th at 7:00 PM ET in Hillcrest 103, titled \"Eugenics and the Promise of Utopia through Artificial General Intelligence.\" I am interested in learning more about her field of study and what she would like to address during the talk. Dr. Gebru is a high-achieving academic working broadly in the field of computer vision. She holds a PhD in Computer Science from Stanford, and she is very active in academia and industry alike. \n",
    "\n",
    "Trained in her doctorial study as a computer scientist, Dr. Gebru works on algorithmic bias and data mining. She has extensive experience working in research teams at Microsoft, Google, and Apple, and she is a recognized voice in artificial intelligence and ethical frameworks, because of the extensive research experience she had, and the projects and programs she involved in. She is a cofounder of Black in AI, and she is the founder of the Distributed Artificial Intelligence Research Institute. She is very influential and recognized, and she is named one of Time's most influential people. She is also named as one of World's 50 Greatest Leaders by Fortune and one of Nature's ten people who shaped science in 2021, according to Wikipedia. She is also active on social media such as LinkedIn, and she is also very active academically, authoring peer reviewed publications and traveling widely and giving talks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary and Reflection about Dr Gebru's previous talk on Fairness, Accountability, Transparency, and Ethics.\n",
    "The thesis of Dr. Gebru’s lecture is that computer vision is a double edged sword, and if used inappropriately, it could greatly increase systematic racism, racial bias, gender bias, and all types of bias in a society, and greatly harm the population for whom the computer vision is used on. Here, there is a lot of responsibility regarding the use of computer vision, and there are a lot of ethical choices to be made. \n",
    "\n",
    "Data, computer vision, and machine learning ethics is a very important topic, and need to be taken into consideration by researchers. For example, a startup called “Faception” is aimed at profiling people and revealing their personality solely based on their facial image and facial expressions. Dr. Gebru invited us to brainstorm what could potentially go wrong here: say, a person is wrongly judged to be angry or hot-tempered, then that person will be denied jobs based on the assessment of this technology called “Faception”. Dr. Gebru went on to talk about HireVue, another startup technology that harnesses artificial intelligence,  facial recognition to screen job candidates, which might be biased against certain minority groups, hence it is unjust and unethical towards the group of people it’s systematically biased against. A third example is Maryland Police department’s usage of facial recognition and screening of protestors and perpetrators, which could lead to all sorts of consequences and arrests. They could even match a protester's profile to their social media accounts, which sounds dreadful, like a nightmare from a sci-fi movie. In conclusion, Dr. Gebru showcased that used carelessly, computer vision and machine learning could do more harm than good.\n",
    "\n",
    "In one sentence, the thing that everyone needs to understand about computer vision as it's used today is that it's a double edged sword, and it could potentially be very biased and harm many people, so it should be used with caution and a dedicated legal, ethical, scientific framework.\n",
    "\n",
    "In conclusion, greater technical advancement carries greater responsiblity, we need more laws, regulations, and ethical considerations when we engage with latest techonology from computer vision and computer science as a whole."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My proposed question for her during Dr. Gebru's talk\n",
    "If everything could start over from 2001, and there is a benevolent social planer who allocates resource efficiently and cares about all humans living on this land, how would you think the field of computer vision would develop differently, and in what ways better, than what we have now in reality? Thanks!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI for social good\n",
    "However, the funds that supports scientific progress come from large corporations and millitary. Where funds come from matters. The cost of not building a model, and they unquestionably assume that it's beneficial, and they simply claim that it is beneficial. Hence, more people from diverse backgrounds in the field could bring more perspectives into the field of AI. \n",
    "\n",
    "### Issue with not participate in Social Media\n",
    "Sometimes people don't participate in social media platforms, and the AI would classify them as outliers, and this is just scary, since using common sense, people should have choices, and they shouldn't be judged like this if they simply do not want to maintain a social media presence. \n",
    "\n",
    "### computer vision, her field\n",
    "what is computer vision being used for? One researcher left the field, that person enjoy working on it, but it's going to be used by the millitary. They spend a lot on electronic boarder walls. Imagine refugees suffering climate catastrophies, climate scientists wish they were activists, since the government spend more money on computer vision for millitary than spending money on climate change related initialtives. \n",
    "\n",
    "One group of scientists from Chicago use computer vision to develop tools to protect the artist instead of giving the tools \n",
    "\n",
    "\n",
    "allocate resouces to give \n",
    "People who lives next to the Nile river, people walk many miles just to get water, not sure if computer vision would exist, general AI might not solve everybody's problems. deep learning need a lot of labeled image data, rise of gig force, people who are not employed, and they are cheap labor to label the images, I don't think system like stable diffusion, take works from artists with no compensation. \n",
    "\n",
    "stable AI, they didn't pay the artists who supplied the pictures, people are suvallienced when migration, the money comes from millitary, and it's used for survallience. Maybe they help artists, like Glaze, which help artists. \n",
    "\n",
    "### being a women of color in the cs, have you ever felt imposter syndrome?\n",
    "remember all those unqualified people with money. You see people with no track records be given air time, all those people, defraud people, get lots airtime, receipts, and no matter how inadequte they feel. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### economic development and open AI\n",
    "millions of people label the data, million of create contents that are feeded to AI such as chatGPT. There's people working in content moderating,  \n",
    "\n",
    "### AGI\n",
    "Artificial General Intelligence. Dr. Gebru went to the website and looked up the definition of AGI, and there's a defintion by Peter Ross, Russel, and many more definitions. Dr. Gebru maintains that the definition is quite vague and general. Then, Dr. Gebru presents one paper about eugenics and AGI that she wrote with her co-authors. Although people often associate eugenics with NAZI germany, Dr. Gebru explains that eugenics is actually a scientific idea that is studied by many scientists after the World War Two. She further explains the difference between positive eugenics and negative eugenics. She introduces the Second-Wave Eugenics, which is characteriszed by Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, Longtermism, etc. This is quite different from negative eugenics, which in a highly summarized way, is about removing \"stupid\" genes from the gene pool. However, the positive eugenics is different, and it is about improving the gene pool, as Dr. Gebru summerizes. Then she quickly covers the big terms in the Second-Wave Eugenics, and she admits that those are quite contraversial ideas, and some of these ideas are quite extreme and she does not agree with those ideas. At one point, she rolls her eyes and shakes her head about some of the absurd comments and view points she presented. Hence, those are pretty contraversial and hot-debated topics. Some recurrent themes include create superior humans that are going to change the universe, which in a absurd and existential way, on a high level summarize some ideology that this field is going. \n",
    "\n",
    "Moreover, she ties these back to the first-wave eugenics, which also contains a lot of controversial ideas. Then Dr. Gebru went on to talk about AGI development, and she discussed the double-edge sword that is AGI. This speech turned very much like a dreadful sci-fi tale that went badly wrong. On one hand, it seems that if every one does it right to build a benevolent AGI, then there's utopia, but if they build a evil AGI, then we have a apocalypse, like straight out of a Terminator movie. \n",
    "\n",
    "### History\n",
    "Dr Gebru went on to retrace the history of AI, and there's ebbs and flows of the term AI. In 1956, AI term is officially coined. Fast forward to 2010, Deepmind was founded, with the same goal as AI, then in 2014, Bostrom's Superintelligence comes out, and Deepmind is bought by Google. Dr. Gebru kept on going to tie AGI Utopia to the themes she has discussed so far. \n",
    "\n",
    "Basically, there's a race to the bottom with many companies pouring in billions of dolalrs into building AGI. It seems like the next big thing, and all major tech companies do not want to lose this race to build AGI. However, there is a lot of worrying themes, since it seems like a horror sci-fi story just like one from the Terminator. Since one tech company is racing to build it, all other companies needs to build it, because this is a winner take all market, so if one company created open AI, then that company dominates the market, and other company basically face the fate of Yahoo and goes out.  \n",
    "\n",
    "\n",
    "\n",
    "### Dr Gebru went on to introduce some good AI researches \n",
    "Dr Gebru maintains that building a single AI is not all there is, one could potentially build many AI that speciallize in different taskes. She discusses several cases of combating harmful hype in natural language processing. Some organizations focus on just build language processing. However, those small companies sometimes have trouble with securing funding, since general AI might could do it all. The Dr. Gebru mentioned some future events such as \"Stochastic Parrot day\" that further explains this hype about natural language processing.\n",
    "\n",
    "She went on to talk about the AGI Apocalypse, which is basically that they are afraid that they are going to build something that is too powerful, like some sci-fi future, and they are going to create \"skynet\", like in Terminator. However, those concerns about build a sci-fi future that is a apocalypse, are actually a distraction from some acute problems with AI, as Dr. Gebru maintains. Hence, Dr Gebru stress that the more acute problem is that people are exploited when large training AI is going on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('ml-0451')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "828d98d954e87c2b5b44e0a5cfd805247874b19ac6d7df6603713eaf15bc89d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
